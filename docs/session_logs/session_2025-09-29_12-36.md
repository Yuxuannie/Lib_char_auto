# Session Summary: 2025-09-29_12-36

## Topic: copy_stage_requirements

[Paste Claude Code's summary here]
# Session Summary: 2025-09-29 - Semiconductor Library Characterization Copy Stage Rebuild Planning

## Session Overview
- **Focus Area**: Requirements gathering and architectural design for rebuilding the 2-run folder COPY stage with modern software engineering practices
- **Duration**: Approximately 2-3 hours of comprehensive planning
- **Status**: Planning/Architecture Design Phase Complete

## Key Questions & Answers

### Questions Asked by Claude Code:

**COPY STAGE WORKFLOW & DEPENDENCIES:**
- What triggers the copy stage execution?
- Are there dependencies between different dir_name processing?
- What's the typical volume and frequency?
- Does copy stage need to complete before RUN stage starts?

**FILESYSTEM CONSTRAINTS & REQUIREMENTS:**
- Can you describe your storage setup (network vs local)?
- What user/group permissions are required?
- Can multiple characterization jobs run simultaneously?
- When/how should temporary directories be cleaned up?

**ERROR SCENARIOS & HANDLING:**
- What are the most common failure scenarios?
- For each failure type, should the system retry, skip, or abort?
- Who needs to be notified of failures and how?
- If copy operation fails partway, should it clean up partial results?

**PERFORMANCE REQUIREMENTS & SLAS:**
- What's typical volume (directories, data size, file counts)?
- What are acceptable runtimes?
- How many parallel copy operations are optimal?
- Integration with LSF - do you need job prioritization?

**INTEGRATION POINTS:**
- What systems call the copy stage?
- What systems depend on the copy output?
- How do you currently manage the 47+ hardcoded paths?
- Which EDA tools read the copied files?

**FOLDER RESTRUCTURING PREFERENCES:**
- Do you prefer gradual migration or clean break?
- Any corporate standards for Python project structure?
- Preference for config files location?
- Preference for test structure location?

### My Answers:

**APPLICATION SCENARIOS:**
- Support 3 scenarios: DFSD Signoff (baseline, ~100 libs max), CTPM Flow (adds advanced features), SCLD Production (future target with AI agents)
- One request at a time, no overlapping jobs for DFSD
- ~50 dirs typical, 1GB each for standard flow

**WORKFLOW & DEPENDENCIES:**
- tcb* directories have NO dependencies - can run in parallel (start with 10 parallel operations)
- MUST complete copy stage before RUN stage starts (Copy ~1 hour, RUN 2-3 days)
- Priority scheduling needed for long-running libs (mb lib, pnnp lib first)

**FILESYSTEM & PATHS:**
- Hardcoded paths problem currently in target reference files, want automated path detection
- Storage architecture details to be provided after evaluation/test run
- C651 (Apple) jobs need special handling in secure chamber
- Each lib char job needs its own directory - no sharing
- Cleanup handled by char*.tcl collaterals

**ERROR HANDLING:**
**ERROR HANDLING:**
- Common failures: Wrong collaterals during setup, inadequate licenses/CPU/disk, partial lib char failures
- Recovery strategy: Abort after timeout, inform user, manual retry preferred
- Failed directories should block subsequent processing
- On partial copy failure: clean up and re-copy to avoid unexpected errors
- Email addresses provided upfront, need monitoring system with metrics/alerts/dashboards

**VERIFICATION & VALIDATION:**
- Need thorough checksums and strict verification system
- Must validate against original requirements before running
- Manual check of new test projects, compare against old completed projects
- Need automated completion detection (currently manual)

**PROJECT PREFERENCES:**
- Clean break with testing checkpoints, manual verification at each stage
- No corporate standards - create own template for future reference
- Config location: project root (easy to review)
- Big-bang replacement preferred (old system not frequently used)

## Architecture & Design Proposals

### Proposed Solutions:

**PROJECT STRUCTURE:**
```
lib_char_auto/
├── config/scenarios/           # Multi-scenario YAML configs (dfsd_signoff.yaml, ctpm_flow.yaml, scld_production.yaml)
├── src/lib_char_auto/
│   ├── core/                  # copy_engine.py, path_resolver.py, file_operations.py, verification.py
│   ├── models/                # library.py, process_corner.py, workflow_config.py
│   ├── services/              # filesystem.py, parallel_executor.py, error_handler.py, notification.py
│   └── utils/                 # logging_config.py, validators.py, retry_mechanisms.py
├── tests/                     # unit/, integration/, fixtures/, mock_data/
├── scripts/                   # copy_stage.py, verify_setup.py
└── docs/                      # architecture/, api/, troubleshooting/
```

**KEY ARCHITECTURAL COMPONENTS:**
- **CopyEngine**: Main orchestrator supporting 3 scenarios with parallel execution
- **PathResolver**: Automated hardcoded path detection and replacement generation
- **VerificationEngine**: Strict validation with checksums before execution
- **ParallelExecutor**: Resource-aware 10-way concurrent library processing
- **ErrorHandler**: Comprehensive error categorization with user-friendly messages

**CONFIGURATION SCHEMA:**
- Scenario-based YAML configs with inheritance (DFSD → CTPM → SCLD)
- Automated path detection patterns to eliminate 47+ hardcoded paths
- Extensible structure supporting progressive feature additions

### Design Decisions Made:
- **Multi-scenario architecture** - Rationale: Support DFSD → CTPM → SCLD progression with extensible design
- **Automated path detection** - Rationale: Eliminate manual pain of 47+ hardcoded paths
- **Strict verification with checksums** - Rationale: Prevent silent failures that cause downstream corruption
- **10-way parallel processing** - Rationale: tcb* directories have no dependencies, can significantly reduce runtime
- **Big-bang replacement with checkpoints** - Rationale: Old system rarely used, want professional upgrade with manual verification gates
- **Mock-based testing strategy** - Rationale: Cannot run actual lib char locally, need comprehensive testing without EDA dependencies

## Code Artifacts Created
- [ ] Comprehensive project structure design
- [x] Configuration schema for 3 scenarios (YAML format)
- [x] Class interface designs for all major components
- [ ] Implementation phases breakdown (4 phases, 8 weeks)
- [x] Testing strategy without local lib char capability

## Technical Discussions

### Challenges Identified:
1. **Testing without EDA tools**: Cannot run actual lib char locally for validation
2. **Automated path detection**: Need to scan reference files and intelligently detect hardcoded paths
3. **Strict verification**: Implementing comprehensive validation before execution
4. **Multi-scenario support**: Creating extensible architecture for 3 different complexity levels
5. **Error handling**: Providing user-friendly messages with root cause analysis
6. **Resource management**: Handling 10-way parallel processing with license/CPU constraints

### Solutions Proposed:
1. **Layered testing approach**: Unit tests with mock data + integration tests + manual server testing at checkpoints
2. **Pattern-based path detection**: Scan .tcl/.inc/.sh files for absolute path patterns, generate replacement maps
3. **Multi-layer verification**: Prerequisites validation + checksum verification + automated completion detection
4. **Inheritance-based configuration**: Base DFSD config extended by CTPM and SCLD scenarios
5. **Categorized error framework**: Map technical errors to user-friendly messages with suggested actions
6. **Resource-aware executor**: Monitor license/CPU availability, implement priority scheduling

## Action Items
- [x] Complete requirements gathering and architecture planning
- [ ] **IMMEDIATE**: Begin Phase 1 implementation (Foundation - project structure, configuration system, path resolution)
- [ ] Create mock reference data structures for testing
- [ ] Implement core CopyEngine with parallel execution framework
- [ ] Develop automated path detection from reference files
- [ ] Build strict verification system with checksums
- [ ] Set up manual testing checkpoints on company server

## Important Context for Next Session
1. **Implementation Phases**: 4-phase approach over 8 weeks with manual verification checkpoints
2. **Testing Constraints**: Cannot run lib char locally - rely on mock data + manual server testing
3. **Critical Requirements**: Eliminate 47+ hardcoded paths, strict verification, 10-way parallel processing
4. **Priority Focus**: Start with Phase 1 (Foundation) - project structure and configuration system
5. **Architecture Principles**: Scenario-based progression, automated path detection, comprehensive error handling

## Notes & Observations
- Current system has ~2,500 lines across 14 Python files with complex semiconductor characterization workflows
- Major pain points: 47+ hardcoded paths, silent failures, no parallel processing, manual verification
- Strong emphasis on user-friendly error messages and root cause analysis
- Need for progressive complexity support (DFSD baseline → CTPM advanced → SCLD production)
- Corporate environment constraints: secure chambers, LSF integration, license servers, network storage
- Success criteria: eliminate manual configuration pain, prevent silent failures, improve performance through parallelization

